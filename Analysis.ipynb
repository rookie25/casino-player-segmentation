{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8d1621-010b-450a-915a-4bff9481dbcf",
   "metadata": {},
   "source": [
    "# Casino Player Segmentation Analysis\n",
    "\n",
    "\n",
    "##  Data Loading and Exploration\n",
    "**Objective:** Load and explore Harvard casino dataset to understand player behavior patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fed266f-daae-4735-852a-a720b4287320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Imports essential libraries for data analysis, visualization, and statistical modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af5ca0c-6fa5-4e38-afe9-4ae20a867953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully!\n",
      "============================================================\n",
      "Total Players: 4,222\n",
      "Total Columns: 20\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.txt'\n",
    "\n",
    "# Loads dataset using tab delimiter (common for .txt files)\n",
    "\n",
    "# Loads dataset with alternative encoding\n",
    "df = pd.read_csv(file_path, sep='\\t', encoding='ISO-8859-1', low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Players: {len(df):,}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c445a900-7fb1-4f4a-806c-9d49f104aef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting TXT to CSV...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m df_convert \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(txt_file, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Saves as CSV\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df_convert\u001b[38;5;241m.\u001b[39mto_csv(csv_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal TXT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_convert)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.csv'"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CONVERT TXT TO CSV (ONE-TIME CONVERSION)\n",
    "# ========================================\n",
    "# Converts the text file to CSV format for easier handling\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Defines file paths\n",
    "txt_file = 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.txt'\n",
    "csv_file = 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.csv'\n",
    "\n",
    "# Reads txt file\n",
    "print(\"Converting TXT to CSV...\")\n",
    "df_convert = pd.read_csv(txt_file, sep='\\t', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Saves as CSV\n",
    "df_convert.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Conversion complete!\")\n",
    "print(f\"Original TXT: {len(df_convert):,} rows\")\n",
    "print(f\"Saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ae116-6fca-4f43-b561-be28d76b9ad1",
   "metadata": {},
   "source": [
    "## Examines the dataset structure, checks for missing values, and generates summary statistics to understand player behavior patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a5158-664c-425b-8fb3-2d2d7ede42cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# STEP 2: LOAD THE DATASET FROM CSV\n",
    "# ========================================\n",
    "# Loads the converted CSV file\n",
    "\n",
    "file_path = 'C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation/data/raw/AnalyticDataSet_VirtualCasinoTXT.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Players: {len(df):,}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"DataFrame is empty: {df.empty}\")\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\nWARNING: DataFrame is empty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47aa969-4183-4c72-949b-717f6fc65dc3",
   "metadata": {},
   "source": [
    "##  Key Variables Analysis\n",
    "Identifies and analyzes the key betting behavior variables that will be used for player segmentation (RFM metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b675102-35d9-4205-a370-9dac2e29d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEY VARIABLES ANALYSIS\n",
    "# ========================================\n",
    "# Examines the key betting behavior metrics for segmentation\n",
    "\n",
    "print(\"KEY BETTING VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Lists the critical columns for RFM analysis\n",
    "key_columns = [\n",
    "    'Pcsumstk',    # Total stakes (Monetary)\n",
    "    'Pcsumday',    # Total active days (Frequency)\n",
    "    'Pclstdate',   # Last active date (Recency)\n",
    "    'Pcsumbet',    # Total number of bets\n",
    "    'Pcnet',       # Net losses/winnings\n",
    "    'Pcab'         # Average bet size\n",
    "]\n",
    "\n",
    "print(\"\\nKey columns for analysis:\")\n",
    "for col in key_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"  - {col}: Available\")\n",
    "    else:\n",
    "        print(f\"  - {col}: NOT FOUND\")\n",
    "\n",
    "print(\"\\nDISTRIBUTION OF KEY METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(df[key_columns].describe())\n",
    "\n",
    "print(\"\\nPLAYER VALUE DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Stakes Range: {df['Pcsumstk'].min():.2f} to {df['Pcsumstk'].max():,.2f} Euros\")\n",
    "print(f\"Average Stakes per Player: {df['Pcsumstk'].mean():,.2f} Euros\")\n",
    "print(f\"Median Stakes per Player: {df['Pcsumstk'].median():,.2f} Euros\")\n",
    "\n",
    "print(f\"\\nTotal Bets Range: {df['Pcsumbet'].min():.0f} to {df['Pcsumbet'].max():,.0f} bets\")\n",
    "print(f\"Average Bets per Player: {df['Pcsumbet'].mean():.0f} bets\")\n",
    "\n",
    "print(f\"\\nActive Days Range: {df['Pcsumday'].min():.0f} to {df['Pcsumday'].max():.0f} days\")\n",
    "print(f\"Average Active Days: {df['Pcsumday'].mean():.1f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a1745-4f0d-4da5-8bb5-dbe8b5817c40",
   "metadata": {},
   "source": [
    "##  Initial Data Visualizations\n",
    "Creates visualizations to understand the distribution of player betting behavior and identify potential segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1024e09-6d18-40dc-b00d-d46e16cc9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates visualizations to explore data distributions and patterns\n",
    "\n",
    "# Sets visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Creates figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Casino Player Behavior Analysis - Initial Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Distribution of Total Stakes\n",
    "axes[0, 0].hist(df['Pcsumstk'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Total Stakes')\n",
    "axes[0, 0].set_xlabel('Total Stakes (Euros)')\n",
    "axes[0, 0].set_ylabel('Number of Players')\n",
    "axes[0, 0].axvline(df['Pcsumstk'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: Distribution of Active Days\n",
    "axes[0, 1].hist(df['Pcsumday'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Distribution of Active Days')\n",
    "axes[0, 1].set_xlabel('Total Active Days')\n",
    "axes[0, 1].set_ylabel('Number of Players')\n",
    "axes[0, 1].axvline(df['Pcsumday'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Distribution of Total Bets\n",
    "axes[0, 2].hist(df['Pcsumbet'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 2].set_title('Distribution of Total Bets')\n",
    "axes[0, 2].set_xlabel('Total Number of Bets')\n",
    "axes[0, 2].set_ylabel('Number of Players')\n",
    "axes[0, 2].axvline(df['Pcsumbet'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# Plot 4: Boxplot of Total Stakes (shows outliers)\n",
    "axes[1, 0].boxplot(df['Pcsumstk'], vert=True)\n",
    "axes[1, 0].set_title('Boxplot: Total Stakes')\n",
    "axes[1, 0].set_ylabel('Total Stakes (Euros)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Scatter plot - Active Days vs Total Stakes\n",
    "axes[1, 1].scatter(df['Pcsumday'], df['Pcsumstk'], alpha=0.5, s=10)\n",
    "axes[1, 1].set_title('Active Days vs Total Stakes')\n",
    "axes[1, 1].set_xlabel('Active Days')\n",
    "axes[1, 1].set_ylabel('Total Stakes (Euros)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Average Bet Size Distribution\n",
    "axes[1, 2].hist(df['Pcab'], bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[1, 2].set_title('Distribution of Average Bet Size')\n",
    "axes[1, 2].set_xlabel('Average Bet Size (Euros)')\n",
    "axes[1, 2].set_ylabel('Number of Players')\n",
    "axes[1, 2].axvline(df['Pcab'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'C:\\Users\\visha\\OneDrive\\Desktop\\Casino Player Segmentation\\images\\initial_exploration.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Visualizations created and saved to images/initial_exploration.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d04f9-88b1-4e52-8ebe-83dc6e34f327",
   "metadata": {},
   "source": [
    "---\n",
    "#  RFM ANALYSIS & PLAYER SEGMENTATION\n",
    "\n",
    "**RFM Analysis** stands for:\n",
    "- **R**ecency: How recently did the player last bet?\n",
    "- **F**requency: How often does the player bet?\n",
    "- **M**onetary: How much does the player wager?\n",
    "\n",
    "This methodology segments players based on their behavioral patterns to identify high-value, engaged, and at-risk player groups.\n",
    "\n",
    "##  Calculate Recency Score\n",
    "Calculates how recently each player was active. More recent activity indicates higher engagement and retention likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36f120-1b5d-40f8-9cd8-122c56d07f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CALCULATE RFM SCORES - COMPLETE\n",
    "# ========================================\n",
    "# Calculates Recency, Frequency, and Monetary scores with proper date parsing\n",
    "\n",
    "print(\"CALCULATING RFM METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Parse dates (format is M/D/YYYY)\n",
    "print(\"\\n1. Parsing dates...\")\n",
    "df['Pclstdate'] = pd.to_datetime(df['Pclstdate'], format='%m/%d/%Y', errors='coerce')\n",
    "reference_date = pd.to_datetime('2007-02-28')\n",
    "\n",
    "# Step 2: Calculate Recency (days since last activity)\n",
    "df['Recency'] = (reference_date - df['Pclstdate']).dt.days\n",
    "print(f\"   Recency calculated: {df['Recency'].min():.0f} to {df['Recency'].max():.0f} days\")\n",
    "print(f\"   Missing: {df['Recency'].isnull().sum()}\")\n",
    "\n",
    "# Step 3: Calculate Frequency (total active days)\n",
    "df['Frequency'] = df['Pcsumday']\n",
    "print(f\"\\n2. Frequency calculated: {df['Frequency'].min():.0f} to {df['Frequency'].max():.0f} days\")\n",
    "print(f\"   Missing: {df['Frequency'].isnull().sum()}\")\n",
    "\n",
    "# Step 4: Calculate Monetary (total stakes)\n",
    "df['Monetary'] = df['Pcsumstk']\n",
    "print(f\"\\n3. Monetary calculated: ${df['Monetary'].min():.2f} to ${df['Monetary'].max():,.2f}\")\n",
    "print(f\"   Missing: {df['Monetary'].isnull().sum()}\")\n",
    "\n",
    "# Step 5: Normalize to 0-100 scale\n",
    "print(\"\\n4. Normalizing scores...\")\n",
    "\n",
    "# Invert Recency (lower days = better = higher score)\n",
    "max_recency = df['Recency'].max()\n",
    "df['R_Score'] = ((max_recency - df['Recency']) / max_recency) * 100\n",
    "\n",
    "# Scale Frequency\n",
    "max_frequency = df['Frequency'].max()\n",
    "df['F_Score'] = (df['Frequency'] / max_frequency) * 100\n",
    "\n",
    "# Scale Monetary\n",
    "max_monetary = df['Monetary'].max()\n",
    "df['M_Score'] = (df['Monetary'] / max_monetary) * 100\n",
    "\n",
    "print(f\"   R_Score: {df['R_Score'].min():.2f} to {df['R_Score'].max():.2f}\")\n",
    "print(f\"   F_Score: {df['F_Score'].min():.2f} to {df['F_Score'].max():.2f}\")\n",
    "print(f\"   M_Score: {df['M_Score'].min():.2f} to {df['M_Score'].max():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RFM SCORES CALCULATED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nSample of RFM scores:\")\n",
    "print(df[['UserID', 'Recency', 'Frequency', 'Monetary', 'R_Score', 'F_Score', 'M_Score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5c6d7-f5c6-4eae-ba00-f0d07b350ac7",
   "metadata": {},
   "source": [
    "##  Calculate Monetary Score\n",
    "Calculates the total amount wagered by each player. Higher monetary value indicates more valuable players to the casino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6ec10-d6bf-4dc7-ae6b-ad54d49ef8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CALCULATE MONETARY SCORE\n",
    "# ========================================\n",
    "# Uses total stakes as monetary measure\n",
    "\n",
    "# Assigns monetary value (already exists as Pcsumstk)\n",
    "df['Monetary'] = df['Pcsumstk']\n",
    "\n",
    "print(\"MONETARY CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nMonetary Statistics:\")\n",
    "print(f\"  Minimum: {df['Monetary'].min():.2f} Euros\")\n",
    "print(f\"  Maximum: {df['Monetary'].max():,.2f} Euros\")\n",
    "print(f\"  Average: {df['Monetary'].mean():,.2f} Euros\")\n",
    "print(f\"  Median: {df['Monetary'].median():,.2f} Euros\")\n",
    "\n",
    "print(\"\\nMonetary Distribution:\")\n",
    "print(df['Monetary'].describe())\n",
    "\n",
    "print(\"\\nPlayer Value Breakdown:\")\n",
    "low_value = len(df[df['Monetary'] < 1000])\n",
    "med_value = len(df[(df['Monetary'] >= 1000) & (df['Monetary'] < 10000)])\n",
    "high_value = len(df[df['Monetary'] >= 10000])\n",
    "\n",
    "print(f\"  Low Value (< 1,000 Euros): {low_value:,} players ({low_value/len(df)*100:.1f}%)\")\n",
    "print(f\"  Medium Value (1,000-9,999 Euros): {med_value:,} players ({med_value/len(df)*100:.1f}%)\")\n",
    "print(f\"  High Value (10,000+ Euros): {high_value:,} players ({high_value/len(df)*100:.1f}%)\")\n",
    "\n",
    "total_value = df['Monetary'].sum()\n",
    "high_value_contribution = df[df['Monetary'] >= 10000]['Monetary'].sum()\n",
    "\n",
    "print(f\"\\nTotal Casino Revenue: {total_value:,.2f} Euros\")\n",
    "print(f\"Revenue from High Value Players: {high_value_contribution:,.2f} Euros ({high_value_contribution/total_value*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nSample of players with Monetary scores:\")\n",
    "print(df[['UserID', 'Pcsumstk', 'Pcsumday']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d4217-c34b-4331-b92e-30aab379b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FIX: RECALCULATE RECENCY\n",
    "# ========================================\n",
    "# Ensures Recency column exists before normalization\n",
    "\n",
    "# Converts last active date to datetime if not already\n",
    "if df['Pclstdate'].dtype == 'object':\n",
    "    df['Pclstdate'] = pd.to_datetime(df['Pclstdate'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "# Defines reference date\n",
    "reference_date = pd.to_datetime('2007-02-28')\n",
    "\n",
    "# Calculates recency\n",
    "df['Recency'] = (reference_date - df['Pclstdate']).dt.days\n",
    "# Assigns frequency and monetary if not already done\n",
    "if 'Frequency' not in df.columns:\n",
    "    df['Frequency'] = df['Pcsumday']\n",
    "    \n",
    "if 'Monetary' not in df.columns:\n",
    "    df['Monetary'] = df['Pcsumstk']\n",
    "\n",
    "print(\"RFM columns verified:\")\n",
    "print(f\"  Recency: {'Recency' in df.columns}\")\n",
    "print(f\"  Frequency: {'Frequency' in df.columns}\")\n",
    "print(f\"  Monetary: {'Monetary' in df.columns}\")\n",
    "print(\"\\nReady for normalization!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c7807-c1bf-4028-b302-74757a1273c3",
   "metadata": {},
   "source": [
    "## Normalize RFM Scores\n",
    "Standardizes RFM scores to the same scale (0-100) to ensure equal weighting in the clustering algorithm. This prevents variables with larger ranges from dominating the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb8fa1-8aae-4b10-b649-c5451ab2b5e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# COMPLETE RFM RECALCULATION\n",
    "# ========================================\n",
    "# Recalculates all RFM metrics from scratch\n",
    "\n",
    "print(\"RECALCULATING RFM METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Calculate Recency\n",
    "print(\"\\n1. Calculating Recency...\")\n",
    "df['Pclstdate'] = pd.to_datetime(df['Pclstdate'], format='%d-%b-%Y', errors='coerce')\n",
    "reference_date = pd.to_datetime('2007-02-28')\n",
    "df['Recency'] = (reference_date - df['Pclstdate']).dt.days\n",
    "\n",
    "print(f\"   Recency range: {df['Recency'].min():.0f} to {df['Recency'].max():.0f} days\")\n",
    "print(f\"   Missing values: {df['Recency'].isnull().sum()}\")\n",
    "\n",
    "# Step 2: Calculate Frequency\n",
    "print(\"\\n2. Calculating Frequency...\")\n",
    "df['Frequency'] = df['Pcsumday']\n",
    "print(f\"   Frequency range: {df['Frequency'].min():.0f} to {df['Frequency'].max():.0f} days\")\n",
    "print(f\"   Missing values: {df['Frequency'].isnull().sum()}\")\n",
    "\n",
    "# Step 3: Calculate Monetary\n",
    "print(\"\\n3. Calculating Monetary...\")\n",
    "df['Monetary'] = df['Pcsumstk']\n",
    "print(f\"   Monetary range: {df['Monetary'].min():.2f} to {df['Monetary'].max():,.2f} Euros\")\n",
    "print(f\"   Missing values: {df['Monetary'].isnull().sum()}\")\n",
    "\n",
    "# Step 4: Normalize scores\n",
    "print(\"\\n4. Normalizing scores to 0-100...\")\n",
    "\n",
    "# Inverts and scales Recency\n",
    "max_recency = df['Recency'].max()\n",
    "df['R_Score'] = ((max_recency - df['Recency']) / max_recency) * 100\n",
    "\n",
    "# Scales Frequency\n",
    "max_frequency = df['Frequency'].max()\n",
    "df['F_Score'] = (df['Frequency'] / max_frequency) * 100\n",
    "\n",
    "# Scales Monetary\n",
    "max_monetary = df['Monetary'].max()\n",
    "df['M_Score'] = (df['Monetary'] / max_monetary) * 100\n",
    "\n",
    "print(f\"   R_Score range: {df['R_Score'].min():.2f} to {df['R_Score'].max():.2f}\")\n",
    "print(f\"   F_Score range: {df['F_Score'].min():.2f} to {df['F_Score'].max():.2f}\")\n",
    "print(f\"   M_Score range: {df['M_Score'].min():.2f} to {df['M_Score'].max():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RFM CALCULATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Missing R_Score: {df['R_Score'].isnull().sum()}\")\n",
    "print(f\"Missing F_Score: {df['F_Score'].isnull().sum()}\")\n",
    "print(f\"Missing M_Score: {df['M_Score'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\nSample of RFM scores:\")\n",
    "print(df[['UserID', 'R_Score', 'F_Score', 'M_Score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8da4b6-1b70-4a4d-9da3-a3fdaa51023d",
   "metadata": {},
   "source": [
    "## Determine Optimal Number of Clusters\n",
    "Uses the Elbow Method to identify the optimal number of player segments. Tests clustering with 2-8 segments and evaluates which provides the best separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c1db8-7228-4de5-b3f0-19b8d9b693c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#  ELBOW METHOD FOR OPTIMAL CLUSTERS\n",
    "# ========================================\n",
    "# Determines the optimal number of player segments\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Prepares data for clustering\n",
    "X = df[['R_Score', 'F_Score', 'M_Score']].values\n",
    "\n",
    "# Tests different numbers of clusters\n",
    "inertias = []\n",
    "K_range = range(2, 9)\n",
    "\n",
    "print(\"Testing different numbers of clusters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Creates elbow plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title('Elbow Method: Optimal Number of Clusters', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "\n",
    "# Adds annotations\n",
    "for i, k in enumerate(K_range):\n",
    "    plt.annotate(f'{inertias[i]:.0f}', \n",
    "                xy=(k, inertias[i]), \n",
    "                xytext=(5, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/visha/OneDrive/Desktop/Casino Player Segmentation//reports/elbow_method.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nElbow plot saved to reports/elbow_method.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Look for the 'elbow' point where the curve bends.\")\n",
    "print(\"Typical optimal range: 4-6 clusters for player segmentation\")\n",
    "print(\"We will use K=5 for clear segment differentiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12726f40-008d-4cb4-a9de-f43f6511decb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
